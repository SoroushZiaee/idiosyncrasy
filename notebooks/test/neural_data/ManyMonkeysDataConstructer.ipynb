{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "451546e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/colorama-0.4.6+computecanada-py2.py3-none-any.whl\n",
      "Installing collected packages: colorama\n",
      "Successfully installed colorama-0.4.6+computecanada\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a57d6b1-8fd7-4167-a538-ebf86e9f0b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "229077aa-a1d3-4dfc-b3f7-5d14d9ce247d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_dir = '/lustre06/project/6067616/soroush1/idiosyncrasy/notebooks/test'\n",
      "parent_dir = '/lustre06/project/6067616/soroush1/idiosyncrasy'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "script_dir = os.path.dirname(os.getcwd())  # Get the directory where the script is located\n",
    "parent_dir = os.path.dirname(script_dir)  # Get the parent directory\n",
    "parent_dir = os.path.dirname(parent_dir)  # Get the parent directory\n",
    "\n",
    "\n",
    "print(f\"{script_dir = }\")\n",
    "print(f\"{parent_dir = }\")\n",
    "\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49b52583-d4b8-48df-9bca-24f1076dfeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-16 03:15:26,845 - INFO - ImageNet module loaded.\n"
     ]
    }
   ],
   "source": [
    "from lightning import LightningDataModule\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "\n",
    "\n",
    "from cka_reg import DATA_PATH\n",
    "from cka_reg.datamodules.datamodules_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f634a2c8-88b2-4ac9-a080-1c68cb593517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.keys() = <KeysViewHDF5 ['bento', 'category_name_HVM_aligned', 'chabo', 'magneto', 'nano', 'solo', 'stimuli', 'tito', 'var']>\n"
     ]
    }
   ],
   "source": [
    "class NeuralDataConstructor:\n",
    "    def __init__(self, hparams, partition_scheme, *args, **kwargs):\n",
    "        self.hparams = hparams\n",
    "        self.partition = Partition(*partition_scheme, seed=hparams.seed)\n",
    "        self.verbose = hparams.verbose\n",
    "\n",
    "    def get_stimuli(self, *args, **kwargs):\n",
    "        # overwrite method with dataset specific operations\n",
    "        raise NameError(\"Method not implemented\")\n",
    "\n",
    "    def get_neural_responses(self, *args, **kwargs):\n",
    "        # overwrite method with dataset specific operations\n",
    "        raise NameError(\"Method not implemented\")\n",
    "\n",
    "    def get_labels(self, *args, **kwargs):\n",
    "        # overwrite method with dataset specific operations\n",
    "        raise NameError(\"Method not implemented\")\n",
    "\n",
    "    @staticmethod\n",
    "    def partition_neurons(X, ntrain, seed=0):\n",
    "        np.random.seed(seed)\n",
    "        idx = np.random.choice(X.shape[1], X.shape[1], replace=False)\n",
    "        return X[:, idx[:ntrain]], X[:, idx[ntrain:]]\n",
    "\n",
    "class _ManyMonkeysDataConstructer(NeuralDataConstructor):\n",
    "\n",
    "    data = h5.File(f\"{DATA_PATH}/neural_data/many_monkeys2.h5\", \"r\")\n",
    "    print(f\"{data.keys() = }\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hparams,\n",
    "        variations=\"All\",\n",
    "        partition_scheme=(640, 540, 100, 0),\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(hparams, partition_scheme, *args, **kwargs)\n",
    "\n",
    "        if variations == \"All\":\n",
    "            # return all stimuli\n",
    "            self.idxs = np.array(range(len(self.data[\"var\"][()])))\n",
    "            assert partition_scheme[0] == 640\n",
    "        if variations == 3:\n",
    "            self.idxs = self.data[\"var\"][()] == 3\n",
    "            assert partition_scheme[0] == 320\n",
    "        if variations == 6:\n",
    "            self.idxs = self.data[\"var\"][()] == 6\n",
    "            assert partition_scheme[0] == 320\n",
    "\n",
    "        self.n_heldout_neurons = 0\n",
    "\n",
    "    def get_stimuli(self, stimuli_partition):\n",
    "        print(f\"{stimuli_partition = }\")\n",
    "        X = self.data[\"stimuli\"][()][self.idxs].transpose(0, 3, 1, 2)\n",
    "        print(f\"{X}\")\n",
    "        # partition the stimuli\n",
    "        X_Partitioned = self.partition(X)[stimuli_partition]\n",
    "        return X_Partitioned\n",
    "\n",
    "    def get_labels(self, stimuli_partition, class_type):\n",
    "        # get label data -- already converted into integers corresponding to HVM category labels\n",
    "        X = self.data[\"category_name_HVM_aligned\"][()][self.idxs]\n",
    "\n",
    "        X_Partitioned = self.partition(X)[stimuli_partition]\n",
    "\n",
    "        return X_Partitioned\n",
    "\n",
    "    def get_neural_responses(\n",
    "        self,\n",
    "        animals,\n",
    "        n_neurons_animal,\n",
    "        n_trials,\n",
    "        neuron_partition,\n",
    "        stimuli_partition,\n",
    "        hparams,\n",
    "    ):\n",
    "        n_neurons_str = \"+\".join(n_neurons_animal)\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f\"constructing {stimuli_partition} data with\\n\"\n",
    "                + f\"animals:{animals}\\n\"\n",
    "                + f\"neurons:{n_neurons_str}\\n\"\n",
    "                + f\"trials:{n_trials}\\n\"\n",
    "            )\n",
    "        # transform \"All\" to all dataset's animals\n",
    "        animals = self.expand(animals)\n",
    "        # only return [:n_neurons] if it's not the heldout set of neurons\n",
    "        n_neurons_animal = (\n",
    "            [int(1e10)] * len(animals)\n",
    "            if (n_neurons_animal == [\"All\"] or neuron_partition != 0)\n",
    "            else n_neurons_animal\n",
    "        )\n",
    "        n_trials = int(1e10) if n_trials == \"All\" else int(n_trials)\n",
    "        neural_responses = []\n",
    "        for animal, n_neurons in zip(animals, n_neurons_animal):\n",
    "            r = self._get_neural_responses(animal, n_trials, neuron_partition, hparams)\n",
    "            selected_neurons = np.random.RandomState(\n",
    "                hparams.seed_select_neurons\n",
    "            ).permutation(r.shape[1])[: int(n_neurons)]\n",
    "            # print(selected_neurons)\n",
    "            r = r[:, selected_neurons]\n",
    "            neural_responses.append(r)\n",
    "        X = np.concatenate(neural_responses, axis=1)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Neural data shape:\\n(stimuli, sites) : {X.shape}\")\n",
    "\n",
    "        temp = self.partition(X)\n",
    "        print(f\"{type(temp) = }\")\n",
    "        print(f\"{temp.keys() = }\")\n",
    "        \n",
    "        X_Partitioned = self.partition(X)[stimuli_partition]\n",
    "        return X_Partitioned\n",
    "\n",
    "    def _get_neural_responses(self, animal, n_trials, neuron_partition, hparams):\n",
    "        animal, region = animal.split(\".\")\n",
    "        X = self.data[animal][region][\"rates\"][()][self.idxs]\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"{animal} {region} shape:\\n(stimuli, sites, trials) : {X.shape}\")\n",
    "\n",
    "        \"\"\"\n",
    "        get subset of neurons to fit/test on. \n",
    "        return_heldout==0 => fitting set,\n",
    "        return_heldout==1 => heldout set\n",
    "        \"\"\"\n",
    "        if self.n_heldout_neurons != 0:\n",
    "            X = self.partition_neurons(\n",
    "                X, X.shape[1] - self.n_heldout_neurons, seed=hparams.seed\n",
    "            )[neuron_partition]\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"(stimuli, sites, trials) : {X.shape}\")\n",
    "\n",
    "        # take mean over trials\n",
    "        X = X[:, :, :n_trials]\n",
    "        X = np.nanmean(X, axis=2)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"(stimuli, sites) : {X.shape}\")\n",
    "\n",
    "        assert ~np.isnan(np.sum(X))\n",
    "        return X\n",
    "\n",
    "    @staticmethod\n",
    "    def expand(animals):\n",
    "        if animals[0] == \"All\":\n",
    "            return [\n",
    "                \"nano.right\",\n",
    "                \"nano.left\",\n",
    "                \"magneto.right\",\n",
    "                \"magneto.left\",\n",
    "                \"bento.right\",\n",
    "                \"bento.left\",\n",
    "                \"solo.left\",\n",
    "                \"tito.right\",\n",
    "                \"tito.left\",\n",
    "                \"chabo.left\",\n",
    "            ]\n",
    "        return animals\n",
    "\n",
    "def ManyMonkeysDataConstructer(hparams):\n",
    "    return _ManyMonkeysDataConstructer(hparams)\n",
    "\n",
    "def ManyMonkeysValDataConstructer(hparams):\n",
    "    return _ManyMonkeysDataConstructer(\n",
    "        hparams, variations=6, partition_scheme=(320, 0, 320, 0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "128fce42-8104-42d0-b234-16c2d383c3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing train data with\n",
      "animals:['nano.right']\n",
      "neurons:All\n",
      "trials:All\n",
      "\n",
      "nano right shape:\n",
      "(stimuli, sites, trials) : (640, 139, 47)\n",
      "(stimuli, sites, trials) : (640, 139, 47)\n",
      "(stimuli, sites) : (640, 139)\n",
      "Neural data shape:\n",
      "(stimuli, sites) : (640, 139)\n",
      "type(temp) = <class 'dict'>\n",
      "temp.keys() = dict_keys(['train', 'test', 'val'])\n",
      "Neural responses shape: (540, 139)\n"
     ]
    }
   ],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# Create minimal hparams\n",
    "hparams = SimpleNamespace(\n",
    "    seed=42,\n",
    "    seed_select_neurons=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Create minimal hparams\n",
    "hparams = SimpleNamespace(\n",
    "    seed=42,\n",
    "    seed_select_neurons=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Initialize data constructor  \n",
    "data_constructor = ManyMonkeysDataConstructer(hparams)\n",
    "\n",
    "# Get neural responses for train split\n",
    "responses = data_constructor.get_neural_responses(\n",
    "   animals=['nano.right'],\n",
    "   n_neurons_animal=['All'], \n",
    "   n_trials='All',\n",
    "   neuron_partition=0,\n",
    "   stimuli_partition=\"train\",\n",
    "   hparams=hparams\n",
    ")\n",
    "\n",
    "print(f\"Neural responses shape: {responses.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
